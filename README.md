# Projet HDFS - Fusion de Petits Fichiers

## ğŸ“‹ Description du Projet

Ce projet implÃ©mente une solution orientÃ©e objets pour rÃ©soudre le **problÃ¨me des petits fichiers** dans les systÃ¨mes distribuÃ©s de type HDFS (Hadoop Distributed File System).

### Le ProblÃ¨me des Petits Fichiers

Dans HDFS, chaque fichier gÃ©nÃ¨re des mÃ©tadonnÃ©es stockÃ©es en mÃ©moire par le NameNode. Un grand nombre de petits fichiers entraÃ®ne:
- **Surcharge mÃ©moire** du NameNode
- **Performances dÃ©gradÃ©es** lors des opÃ©rations de lecture/Ã©criture
- **CoÃ»t Ã©levÃ©** de gestion des mÃ©tadonnÃ©es

### La Solution

Ce programme regroupe les petits fichiers en **clusters** en utilisant un algorithme de **clustering hiÃ©rarchique agglomÃ©ratif** avec la mÃ©thode **single-linkage**, permettant de:
- RÃ©duire le nombre de fichiers de mÃ©tadonnÃ©es
- Minimiser la surcharge du NameNode
- Optimiser l'utilisation du stockage

---

## ğŸ§® MÃ©thode de Clustering UtilisÃ©e

### Algorithme: Clustering HiÃ©rarchique AgglomÃ©ratif

**Principe:**
1. **Initialisation**: Chaque fichier commence comme un cluster individuel
2. **ItÃ©ration**: Ã€ chaque Ã©tape:
   - Trouver les deux clusters les plus proches
   - VÃ©rifier la contrainte de taille: `taille_totale â‰¤ 128 MB`
   - Si OK â†’ fusionner les clusters
   - Sinon â†’ marquer comme non fusionnable
3. **Terminaison**: Quand aucune fusion n'est plus possible

### Distance Entre Fichiers

La distance est calculÃ©e **uniquement sur la taille**:

```
distance(fichier_i, fichier_j) = |taille_i - taille_j|
```

### MÃ©thode de Linkage: Single-Linkage

La distance entre deux clusters A et B est le **minimum** des distances entre leurs Ã©lÃ©ments:

```
distance(A, B) = min(distance(fichier_i, fichier_j))
                 pour tout fichier_i âˆˆ A, fichier_j âˆˆ B
```

---

## ğŸ—ï¸ Structure du Projet

```
projet_hdfs/
â”‚
â”œâ”€â”€ models/                      # Classes de donnÃ©es
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ small_file.py           # Classe SmallFile (nom, taille)
â”‚   â””â”€â”€ cluster.py              # Classe Cluster (groupe de fichiers)
â”‚
â”œâ”€â”€ core/                        # Algorithmes principaux
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ distance_matrix.py      # Calcul de la matrice de distance
â”‚   â”œâ”€â”€ clustering.py           # Clustering hiÃ©rarchique agglomÃ©ratif
â”‚   â””â”€â”€ merger.py               # Fusion physique des fichiers
â”‚
â”œâ”€â”€ data_io/                     # EntrÃ©es/Sorties
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_generator.py       # GÃ©nÃ©ration de fichiers de test
â”‚   â””â”€â”€ metadata_writer.py      # Ã‰criture des mÃ©tadonnÃ©es JSON
â”‚
â”œâ”€â”€ output/                      # Dossier de sortie (crÃ©Ã© automatiquement)
â”‚   â”œâ”€â”€ cluster_*.bin           # Fichiers fusionnÃ©s
â”‚   â”œâ”€â”€ cluster_*_metadata.json # MÃ©tadonnÃ©es individuelles
â”‚   â”œâ”€â”€ clusters_summary.json   # RÃ©sumÃ© de tous les clusters
â”‚   â””â”€â”€ detailed_report.txt     # Rapport dÃ©taillÃ©
â”‚
â”œâ”€â”€ main.py                      # Point d'entrÃ©e du programme
â”œâ”€â”€ README.md                    # Ce fichier
â””â”€â”€ requirements.txt             # DÃ©pendances Python
```

---

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.7 ou supÃ©rieur
- Aucune bibliothÃ¨que externe requise (bibliothÃ¨que standard uniquement)

### Installation

```bash
# Cloner ou tÃ©lÃ©charger le projet
cd projet_hdfs

# Optionnel: crÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances (aucune pour ce projet)
pip install -r requirements.txt
```

---

## ğŸš€ Utilisation

### ExÃ©cution du Programme

```bash
python main.py
```

### Modes d'ExÃ©cution

Le programme propose plusieurs modes:

1. **Exemple 1**: ScÃ©nario rÃ©aliste avec fichiers mixtes
2. **Exemple 2**: Liste personnalisÃ©e de fichiers
3. **Exemple 3**: ProblÃ¨me des petits fichiers
4. **Mode interactif**: Configuration personnalisÃ©e
5. **Tous les exemples**: ExÃ©cution sÃ©quentielle

---

## ğŸ“Š Exemple d'EntrÃ©e

### GÃ©nÃ©ration Automatique

```python
from io.file_generator import FileGenerator

generator = FileGenerator()
files = generator.generate_realistic_scenario("mixed")
```

GÃ©nÃ¨re un ensemble de fichiers comme:
```
file_0001.dat (5.00 MB)
file_0002.dat (10.00 MB)
file_0003.dat (20.00 MB)
...
```

### CrÃ©ation Manuelle

```python
from models.small_file import SmallFile

files = [
    SmallFile("doc1.txt", 10.0),
    SmallFile("img1.jpg", 25.0),
    SmallFile("video.mp4", 45.0),
]
```

---

## ğŸ“¤ Exemple de Sortie

### Fichiers FusionnÃ©s

```
output/
â”œâ”€â”€ cluster_1.bin        # Cluster 1 (96.5 MB, 8 fichiers)
â”œâ”€â”€ cluster_2.bin        # Cluster 2 (120.0 MB, 5 fichiers)
â””â”€â”€ cluster_3.bin        # Cluster 3 (78.3 MB, 6 fichiers)
```

### MÃ©tadonnÃ©es JSON

**`clusters_summary.json`:**
```json
{
  "total_clusters": 3,
  "clusters": [
    {
      "cluster_id": 1,
      "files": ["file_0001.dat", "file_0003.dat", "file_0005.dat"],
      "file_count": 3,
      "size_total_mb": 96.5
    },
    {
      "cluster_id": 2,
      "files": ["file_0002.dat", "file_0004.dat"],
      "file_count": 2,
      "size_total_mb": 120.0
    }
  ],
  "summary": {
    "total_files": 19,
    "total_size_mb": 294.8,
    "file_reduction_rate_percent": 84.21
  }
}
```

### Rapport DÃ©taillÃ©

**`detailed_report.txt`:**
```
================================================================================
RAPPORT DE FUSION DE FICHIERS HDFS
================================================================================

Nombre de fichiers originaux: 19
Nombre de clusters crÃ©Ã©s: 3
Taux de rÃ©duction: 84.21%

--------------------------------------------------------------------------------
DÃ‰TAILS DES CLUSTERS
--------------------------------------------------------------------------------

Cluster ID: 1
  Nombre de fichiers: 8
  Taille totale: 96.50 MB
  Fichiers:
    - file_0001.dat (5.00 MB)
    - file_0003.dat (10.00 MB)
    ...
```

---

## ğŸ¯ Contraintes Techniques

### ImplÃ©mentation

âœ… **Programmation orientÃ©e objets** stricte  
âœ… **Aucune bibliothÃ¨que externe** de clustering (pas scipy, pas scikit-learn)  
âœ… **Algorithme manuel** complÃ¨tement implÃ©mentÃ©  
âœ… **MÃ©thode single-linkage** respectÃ©e  
âœ… **Contrainte de taille** de 128 MB par cluster  
âœ… **Distance euclidienne** basÃ©e uniquement sur la taille  

### Classes Principales

- `SmallFile`: ReprÃ©sente un fichier (nom, taille)
- `Cluster`: Groupe de fichiers
- `DistanceMatrix`: Matrice de distance entre clusters
- `AgglomerativeClustering`: Algorithme de clustering
- `FileMerger`: Fusion physique des fichiers
- `MetadataWriter`: Ã‰criture des mÃ©tadonnÃ©es

---

## ğŸ“ˆ Performances

### ComplexitÃ©

- **Temps**: O(nÂ³) dans le pire cas
  - nÂ² paires Ã  considÃ©rer
  - n itÃ©rations maximum
  
- **Espace**: O(nÂ²) pour la matrice de distance

### Optimisations Possibles

- Utiliser une structure de donnÃ©es plus efficace (heap)
- ImplÃ©menter un cache pour les distances
- ParallÃ©liser le calcul de la matrice

---

## ğŸ”§ Configuration

### Modifier la Taille Maximale

Dans `main.py`:
```python
clustering = AgglomerativeClustering(max_cluster_size_mb=256.0)  # 256 MB
```

### Changer le RÃ©pertoire de Sortie

```python
merger = FileMerger(output_dir="mes_resultats")
metadata_writer = MetadataWriter(output_dir="mes_resultats")
```

---

## ğŸ“ Exemples d'Utilisation AvancÃ©e

### Utiliser l'API Programmatique

```python
from models.small_file import SmallFile
from core.clustering import AgglomerativeClustering
from core.merger import FileMerger
from data_io.metadata_writer import MetadataWriter

# 1. CrÃ©er des fichiers
files = [
    SmallFile("data1.csv", 15.0),
    SmallFile("data2.csv", 18.0),
    SmallFile("img.jpg", 30.0),
]

# 2. Clustering
clustering = AgglomerativeClustering(max_cluster_size_mb=128.0)
clusters = clustering.fit(files)

# 3. Fusion
merger = FileMerger(output_dir="output")
merger.merge_all_clusters(clusters)

# 4. MÃ©tadonnÃ©es
writer = MetadataWriter(output_dir="output")
writer.write_all_metadata(clusters)
```

### GÃ©nÃ©rer un ScÃ©nario PersonnalisÃ©

```python
from data_io.file_generator import FileGenerator

generator = FileGenerator()

# Distribution personnalisÃ©e
distribution = {
    5: 20,   # 20 fichiers de 5 MB
    15: 10,  # 10 fichiers de 15 MB
    30: 5,   # 5 fichiers de 30 MB
}

files = generator.generate_with_distribution(distribution)
```

---

## ğŸ§ª Tests

### VÃ©rifier le Fonctionnement

ExÃ©cutez le programme avec l'exemple 1:
```bash
python main.py
# Choisir: 1
```

VÃ©rifiez les fichiers dans le dossier `output/`:
- Fichiers `.bin` (fichiers fusionnÃ©s)
- Fichiers `.json` (mÃ©tadonnÃ©es)
- Fichiers `.txt` (rapports)

---

## ğŸ¤ Contribution

### Architecture du Code

Le code est organisÃ© en modules indÃ©pendants:
- **models**: Structures de donnÃ©es
- **core**: Algorithmes
- **data_io**: GÃ©nÃ©ration et Ã©criture

### Ajouter une FonctionnalitÃ©

1. Identifier le module appropriÃ©
2. CrÃ©er une nouvelle classe ou mÃ©thode
3. Documenter avec des docstrings
4. Mettre Ã  jour le `README.md`

---

## ğŸ“š RÃ©fÃ©rences

### HDFS Small Files Problem

- [Apache Hadoop Documentation](https://hadoop.apache.org/)
- [The Small Files Problem in HDFS](https://blog.cloudera.com/the-small-files-problem/)

### Clustering HiÃ©rarchique

- Algorithme: Agglomerative Hierarchical Clustering
- Linkage: Single-linkage (nearest neighbor)
- Distance: Euclidienne (taille des fichiers)

---

## ğŸ“„ Licence

Ce projet est fourni Ã  des fins Ã©ducatives.

---

## ğŸ‘¨â€ğŸ’» Auteur

Projet acadÃ©mique - M1 Data Science  
Date: Novembre 2025

---

## ğŸ“ Notes PÃ©dagogiques

### Concepts IllustrÃ©s

1. **Programmation orientÃ©e objets**
   - Encapsulation
   - HÃ©ritage conceptuel
   - Polymorphisme

2. **Algorithmes de clustering**
   - Clustering hiÃ©rarchique
   - Matrice de distance
   - MÃ©thodes de linkage

3. **SystÃ¨mes distribuÃ©s**
   - ProblÃ¨me des petits fichiers
   - Optimisation du stockage
   - Gestion des mÃ©tadonnÃ©es

### Points ClÃ©s

- âœ… Aucune bibliothÃ¨que externe de ML
- âœ… ImplÃ©mentation complÃ¨te de l'algorithme
- âœ… Code commentÃ© et documentÃ©
- âœ… Architecture modulaire
- âœ… Gestion propre des fichiers

---

**Bon clustering ! ğŸš€**
